# A-Hybridized-Deep-Learning-Method-for-Bengali-Image-Captioning

### Dataset:

FLickr8k dataset were used in this experiment. This dataset consist of 8000 images. Each of these 8000 images has 5 captions in English. We coverted these English captions to Bengali using Google translator than manually corrected sementics error in each Bengali tokens. We utilized two diffrent length that is 4000 and 8000 of Flickr dataset in our experiment. Both of the Bengali dataset are provided here.

You can download the images of Flickr8k dataset from here: https://www.kaggle.com/adityajn105/flickr8k/activity

### Model: 

We utilized Encoder-Decoder architecture for Image Captioning in Bengali. The main focus of the experiment was to concatenate two Embedding layer pretarined GloVe in Bengali and fastText and observe how accurate Bengali caption is generated by the model.


### Metric:

We utilized the BLEU metric to evaluate the captions generated by our model.

## Code

Two codes are given here one is a geerdy approch to evaluate Bengali caption generated using our hybrid model. Another code uses Beam search to evaluate Bengali caption generated using our hybrid model.
